# The Philosopher's Stone: One Science to Bend Them All

> Rewritten as the original had issues with breath and flow

I've often been involved as a passive listener in groups where I didn't have much resonance: mainly shared beliefs. I participated nonetheless because I thought some perspective about their creed was interesting. On these endeavors, I would often challenge myself with a question: _Why would this group exist in the first place, and what about this group is symptomatic of society overall?_

A group I would like to juxtapose with the main idea of this entry is the New Age movement. At its idealistic core, it portrays humankind as a project of sorts, in which integration with a higher responsibility—and thus contact with other "alien" species—would be possible only if mankind achieved some sort of transcendental quality. Namely, mastery over an overused term with which we are all familiar: love.

The "alien conundrum" that grabs most people's attention in this set of beliefs I didn't find interesting, because it essentially delegates the task of salvation to a foreign agency. This is a pattern we have already been through multiple times: the idea that a messiah can do the hard homework for us. In sheer honesty, I must confess that I don't care about aliens because my life's fixation is on what people are doing and how their doing becomes an identity or a definition of who they are, and not what they say. In this sense, I consider my life's responsibility to reframe problems so people can jump to a different perspective—a manner in which the battlefield is tilted to their advantage so _they are willing to do what they were born to do._

But I digress. What's truly worth rescuing about the New Age in the current times of accelerationism is its proposition of morality and how, in a celestial conflict of sorts, there's a fundamental distinction between "alien alliances" based on their relationship with regards to authority. Here, morality falls into classical binarism: there are the good guys, who allow you to live your life with sovereignty and want you to learn lessons on your own. No matter how painful the experience, they never offer a helping hand because each last second has infinite value to them. And then there are the "dark species," in which morality is a function of stability, practicality, and authority.

This binarism is very interesting because it reflects a fundamental aspect of reality, which is our relationship to authority. In essence, the "bad guys" want you to become an embodiment of your boss: an appendix or an extension. The "good guys" want you to learn how to become like your current leader—moving up through a hierarchy as a measure of how you can be of service to others: paradoxically the higher you are, the more inverted the pyramid is.

## Technique and the Moral Binary
This morality binarism, I learned, is the fundamental key to how each of the sides relates to technique and, by extension, technology. The "good species" forbid the use of computers, while the dark species employ mechanisms like computers and A.I. to their fullest extent. The reason why is simple: the code that goes into a computer program is essentially a means to communicate full ownership and authority over a subject—the subject in this case being the computer. Thus, the controlled subject is a perfect extension of the author.

The "good guys," on the other hand, rely on interfacing with reality through the act of speaking while letting things keep their original essence. When you are using a computer, you are telling it with **cabal precision** what to do. But in the other perspective, you are allowing the thing you wish to control not to become alienated by your own authority: you let it be, but talk it through an argument so it decides to temporarily align with your intentions. Nature then becomes your ally because you are worth it, not because you coerce it.

Computers are, unsurprisingly, considered to be completely evil in the New Age moral dichotomy. Not because computers are evil by an attribute of their essence as techniques (I personally love computers and LLMs), but by the power they enable as they express authority in a way that allows no exceptions. The problem, however, is that morality can be mostly reduced to deciding what to do with time provided a context. A good understanding of context that is far-reaching is full of exceptions. Namely, a lot of people over the history of mankind had to endure "looking bad" for the right cause because they understood causality farther than anybody else. The bad guys will often "look good" doing whatever they are doing but miss the mark at the long game of evolution, which is the game of learning.

Here, the good guys in this galactic cosmovision seem to understand it better because they proverbially want the game of learning to go on forever, and they reflect this understanding properly in the means they technically operate. By the account of some authors, they store memory in living crystals instead of hard drives, their "spaceships" are living beings, and their warfare is waged through psychic means, persuading reality through speech to rain fire on enemies—not laser blasters or nuclear bombs.

## Learning, Wisdom, and the Human Hack


Essentially, this moral difference opens up a debate on the nature of learning itself. New Age proponents often frame A.I. as the science of perfect authority and thus the science of evil. But this misses the point. The mathematics of machine learning are merely a formal description of a universal process: learning. Learning is the act of gathering fitness with regards to a problem. Wisdom, its highest form, is what splits the sea between the novice and the master; a wise person sees the solution to a hard problem in a glance, while the inexperienced spend an eternity figuring it out. Learning is the foundation of all technique, and thus the foundation of reality.

The true moral question is not about the mathematics, but its *implementation*. To execute learning cabalistically on a computer is to pursue the "dark" path of absolute authority. The machine, a perfect extension of its author, learns without exception and without essence. This is why a single ethical screw-up in an AI system is magnified catastrophically compared to an analog society. My guess is that's why the "good species" ditched computers long ago.

So if machine learning on a computer is the path of coercion, what is the path of persuasion for a human being?

The answer lies in our own learning function: our personality. The math of machine learning may be agnostic, but in anthropocentric terms, our capacity to learn is filtered through the lens of who we are. It follows, then, that any tool which allows your persona to be contorted into a different one—even temporarily—is the key to unlocking the reality of humanity itself. This is where personality theories, for all their scientific flaws, become a very strong hack.

Critics rightly point out that frameworks like Myers-Briggs oversimplify human complexity into rigid, often inaccurate boxes. But they miss the point. Their highest value is not in providing a static, true label of "who you are." Their true power lies in offering an operational framework to *simulate being someone else* and understanding that subjectivity is a trap to completitude and fulfillment. They are a technique for bending your own perspective.

You can see this clearly in multiplayer games where a player is asked to specialize into a class—a warrior, a mage, a rogue. The player who specializes yet has played all the other classes is the best player. They will win you the match because they don't just know the abilities of other classes; they have *inhabited their perspective*. They anticipate scenarios because they have lived those scenarios from multiple points of view. The "good guys of the galaxy" see it the same way. One gets a higher ranking in their hierarchy by measure of how much one understands other people by *living their lives*.

This is the hack. For the "quant" person, learning theory with its trinary prototype of reality (function, weights, and label) is visible everywhere - i recently came to discover an interesting paper on one of the many theories of everything: [the universe as a neural net with the langugae of the percepetron used to transpile general relativity and quantum mechanics](https://arxiv.org/abs/2008.01540). However machine learning for everyone else, becomes usable in the frame of personality frameworks. They are a tool for deliberately disassembling the self and use new forms of "being" to gather valuable perspectives from the worlds of other people in a functional sort of way. Bending your perspective to the limits of perception enhances learning in ways we are yet to completely understand. As a closing statement: i think machine learning and AI call for an update on the reach of our moral perception, but i fear our reach to see into the future is not potent enough to implement these systems with true foresight and good judgement - a lot of people on the elite side, have interests which far exceed human sufficiency and thats when the danger starts lurking.

Thanks for reading.